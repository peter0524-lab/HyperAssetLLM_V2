"""
OpenAI ChatGPT Client for stock analysis service
"""

import aiohttp
import json
import asyncio
import logging
import re
from typing import Dict, List, Optional, Any
from datetime import datetime

logger = logging.getLogger(__name__)


class OpenAIClient:
    """OpenAI ChatGPT í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None, model: str = "gpt-4o-mini"):
        self.api_key = api_key
        self.base_url = base_url or "https://api.openai.com/v1/chat/completions"
        self.model = model
        self.session = None
        
    async def _get_session(self):
        """HTTP ì„¸ì…˜ ìƒì„±"""
        if self.session is None or self.session.closed:
            self.session = aiohttp.ClientSession()
        return self.session
    
    async def close(self):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        if self.session and not self.session.closed:
            await self.session.close()
    
    def is_available(self) -> bool:
        """API í‚¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.api_key is not None
    
    def get_client_info(self) -> Dict[str, Any]:
        """í´ë¼ì´ì–¸íŠ¸ ì •ë³´ ë°˜í™˜"""
        return {
            "client_type": "OpenAIClient",
            "has_api_key": self.api_key is not None,
            "base_url": self.base_url,
            "model": self.model
        }
    
    async def generate_response(self, prompt: str, **kwargs) -> Optional[str]:
        """OpenAI APIë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ìƒì„±"""
        try:
            if not self.is_available():
                logger.warning("âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            session = await self._get_session()
            
            # OpenAI API ìš”ì²­ í˜•ì‹
            payload = {
                "model": kwargs.get("model", self.model),
                "messages": [
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ì™€ ê³µì‹œë¥¼ ë¶„ì„í•˜ì—¬ íˆ¬ììì—ê²Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": kwargs.get("temperature", 0.3),
                "max_tokens": kwargs.get("max_tokens", 1000),
                "top_p": kwargs.get("top_p", 0.8),
                "frequency_penalty": kwargs.get("frequency_penalty", 0.0),
                "presence_penalty": kwargs.get("presence_penalty", 0.0),
                "stop": kwargs.get("stop_sequences", None)
            }
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            logger.debug(f"ğŸ”— OpenAI API í˜¸ì¶œ: {self.base_url}")
            
            async with session.post(
                self.base_url,
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=60)
            ) as response:
                
                if response.status == 200:
                    raw_response = await response.json()
                    logger.debug("âœ… OpenAI API í˜¸ì¶œ ì„±ê³µ")
                    
                    # OpenAI ì‘ë‹µ íŒŒì‹±
                    if "choices" in raw_response and raw_response["choices"]:
                        content = raw_response["choices"][0]["message"]["content"]
                        return content
                    else:
                        logger.warning("âš ï¸ OpenAI ì‘ë‹µì— choicesê°€ ì—†ìŠµë‹ˆë‹¤.")
                        return None
                else:
                    error_text = await response.text()
                    logger.error(f"âŒ OpenAI API ì˜¤ë¥˜ {response.status}: {error_text}")
                    return None
                    
        except asyncio.TimeoutError:
            logger.error("âŒ OpenAI API íƒ€ì„ì•„ì›ƒ")
            return None
        except Exception as e:
            logger.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    async def generate_text(self, prompt: str, max_tokens: int = 1000) -> str:
        """í˜¸í™˜ì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ìƒì„± ë©”ì„œë“œ"""
        response = await self.generate_response(prompt, max_tokens=max_tokens)
        return response if response else "í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨"
    
    async def analyze_news_impact(self, news_content: str, stock_name: str) -> Dict:
        """ë‰´ìŠ¤ ì˜í–¥ë„ ë¶„ì„ (OpenAI ì „ìš© í”„ë¡¬í”„íŠ¸)"""
        prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ ì¦ê¶Œì‹œì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë‰´ìŠ¤ê°€ {stock_name}ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë‰´ìŠ¤ ë‚´ìš©: {news_content}

ë¶„ì„ ìš”ì²­ì‚¬í•­:
1. ì˜í–¥ë„ ì ìˆ˜ (0.0-1.0): ì´ ë‰´ìŠ¤ê°€ ì£¼ê°€ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì˜ ê°•ë„
2. ë°©í–¥ì„± (1-5): 1=ë§¤ìš°ë¶€ì •, 2=ë¶€ì •, 3=ì¤‘ë¦½, 4=ê¸ì •, 5=ë§¤ìš°ê¸ì •
3. ì‹œì¥ ì˜í–¥ ë¶„ì„: êµ¬ì²´ì ì¸ ì˜í–¥ ìš”ì¸ê³¼ ë©”ì»¤ë‹ˆì¦˜
4. íˆ¬ìì ì•Œë¦¼ ë©”ì‹œì§€: í…”ë ˆê·¸ë¨ ë°œì†¡ìš© ê°„ê²°í•œ ë©”ì‹œì§€

ì‘ë‹µ í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”:
ì˜í–¥ë„ì ìˆ˜: 0.XX
ë°©í–¥ì„±ì ìˆ˜: X
ì‹œì¥ì˜í–¥: (ìƒì„¸ ë¶„ì„ ë‚´ìš©)
ì•Œë¦¼ë©”ì‹œì§€: (í…”ë ˆê·¸ë¨ìš© ë©”ì‹œì§€)
"""
        
        response = await self.generate_response(prompt, max_tokens=800)
        if not response:
            return {
                "impact_score": 0.5,
                "direction_score": 3,
                "analysis": "ë¶„ì„ ì‹¤íŒ¨",
                "message": "ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨"
            }
        
        # ì‘ë‹µ íŒŒì‹±
        try:
            # ì˜í–¥ë„ ì ìˆ˜ ì¶”ì¶œ (0.0-1.0)
            impact_match = re.search(r'ì˜í–¥ë„ì ìˆ˜:\s*([0-9.]+)', response)
            impact_score = float(impact_match.group(1)) if impact_match else 0.5
            impact_score = max(0.0, min(1.0, impact_score))  # ë²”ìœ„ ì œí•œ
            
            # ë°©í–¥ì„± ì ìˆ˜ ì¶”ì¶œ (1-5)
            direction_match = re.search(r'ë°©í–¥ì„±ì ìˆ˜:\s*([1-5])', response)
            direction_score = int(direction_match.group(1)) if direction_match else 3
            
            # ì‹œì¥ì˜í–¥ ì¶”ì¶œ
            market_match = re.search(r'ì‹œì¥ì˜í–¥:\s*(.+?)(?=\n|ì•Œë¦¼ë©”ì‹œì§€:|$)', response, re.DOTALL)
            analysis = market_match.group(1).strip() if market_match else response[:200]
            
            # ì•Œë¦¼ë©”ì‹œì§€ ì¶”ì¶œ
            message_match = re.search(r'ì•Œë¦¼ë©”ì‹œì§€:\s*(.+?)(?=\n|$)', response)
            message = message_match.group(1).strip() if message_match else f"{stock_name} ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ"
            
            return {
                "impact_score": impact_score,
                "direction_score": direction_score,
                "analysis": analysis,
                "message": message
            }
        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ ë¶„ì„ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "impact_score": 0.5,
                "direction_score": 3,
                "analysis": response[:200],
                "message": f"{stock_name} ê´€ë ¨ ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ"
            }
    
    async def analyze_disclosure_impact(self, disclosure_content: str, stock_name: str) -> Dict:
        """ê³µì‹œ ì˜í–¥ë„ ë¶„ì„ (OpenAI ì „ìš© í”„ë¡¬í”„íŠ¸)"""
        prompt = f"""
ë‹¹ì‹ ì€ ê³µì‹œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê³µì‹œê°€ {stock_name}ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ê³µì‹œ ë‚´ìš©: {disclosure_content}

ë¶„ì„ ìš”ì²­ì‚¬í•­:
1. ê³µì‹œ ìš”ì•½ (3ì¤„ ì´ë‚´): í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ
2. ì˜í–¥ë„ ì ìˆ˜ (0.0-1.0): 0=ë¬´ì˜í–¥, 0.5=ì¤‘ê°„ì˜í–¥, 1.0=ë§¤ìš°ë†’ì€ì˜í–¥
3. ê°ì • íŒë‹¨ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½): íˆ¬ì ê´€ì ì—ì„œì˜ ê°ì •
4. ê°ì • íŒë‹¨ ê·¼ê±°: ê¸ì •/ë¶€ì • íŒë‹¨ ì´ìœ 
5. ì£¼ìš” í‚¤ì›Œë“œ: í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ
6. ì˜ˆìƒ ì£¼ê°€ ì˜í–¥: ìƒìŠ¹/í•˜ë½/ë³´í•©
7. ì˜í–¥ ì§€ì† ì‹œê°„: ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸°

ì‘ë‹µì„ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "ê³µì‹œìš”ì•½": "ìš”ì•½ë‚´ìš©",
    "ì˜í–¥ë„ì ìˆ˜": 0.XX,
    "sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
    "sentimentíŒë‹¨ê·¼ê±°": "íŒë‹¨ê·¼ê±°",
    "ì£¼ìš”í‚¤ì›Œë“œ": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
    "ì˜ˆìƒì£¼ê°€ì˜í–¥": "ìƒìŠ¹/í•˜ë½/ë³´í•©",
    "ì˜í–¥ì§€ì†ì‹œê°„": "ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸°"
}}
"""
        
        response = await self.generate_response(prompt, max_tokens=1000)
        if not response:
            return {
                "summary": "ë¶„ì„ ì‹¤íŒ¨",
                "impact_score": 0.5,
                "sentiment": "ì¤‘ë¦½",
                "sentiment_reason": "ë¶„ì„ ì‹¤íŒ¨",
                "keywords": ["ë¶„ì„", "ì‹¤íŒ¨", "ì¬ì‹œë„"],
                "expected_impact": "ë³´í•©",
                "impact_duration": "ì¤‘ê¸°"
            }
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            # JSON ì¶”ì¶œ ë° íŒŒì‹±
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                parsed = json.loads(json_str)
                
                return {
                    "summary": parsed.get("ê³µì‹œìš”ì•½", "ìš”ì•½ ì—†ìŒ"),
                    "impact_score": float(parsed.get("ì˜í–¥ë„ì ìˆ˜", 0.5)),
                    "sentiment": parsed.get("sentiment", "ì¤‘ë¦½"),
                    "sentiment_reason": parsed.get("sentimentíŒë‹¨ê·¼ê±°", "íŒë‹¨ ê·¼ê±° ì—†ìŒ"),
                    "keywords": parsed.get("ì£¼ìš”í‚¤ì›Œë“œ", ["ê³µì‹œ", "ë¶„ì„", "ì˜í–¥"]),
                    "expected_impact": parsed.get("ì˜ˆìƒì£¼ê°€ì˜í–¥", "ë³´í•©"),
                    "impact_duration": parsed.get("ì˜í–¥ì§€ì†ì‹œê°„", "ì¤‘ê¸°")
                }
            else:
                # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ íŒŒì‹±
                return self._parse_disclosure_text(response, stock_name)
                
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ì „í™˜: {e}")
            return self._parse_disclosure_text(response, stock_name)
    
    def _parse_disclosure_text(self, response: str, stock_name: str) -> Dict:
        """ê³µì‹œ ë¶„ì„ í…ìŠ¤íŠ¸ íŒŒì‹± (JSON ì‹¤íŒ¨ì‹œ fallback)"""
        try:
            # ì˜í–¥ë„ ì ìˆ˜ ì¶”ì¶œ
            impact_match = re.search(r'ì˜í–¥ë„.*?([0-9.]+)', response)
            impact_score = float(impact_match.group(1)) if impact_match else 0.5
            
            # ê°ì • ì¶”ì¶œ
            sentiment = "ì¤‘ë¦½"
            if "ê¸ì •" in response:
                sentiment = "ê¸ì •"
            elif "ë¶€ì •" in response:
                sentiment = "ë¶€ì •"
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords_match = re.search(r'í‚¤ì›Œë“œ.*?[:ï¼š]\s*(.+?)(?=\n|$)', response)
            if keywords_match:
                keywords_text = keywords_match.group(1)
                keywords = [k.strip().strip('"[]') for k in re.split(r'[,ï¼Œ]', keywords_text)]
                keywords = [k for k in keywords if k][:3]
            else:
                keywords = ["ê³µì‹œ", "ë¶„ì„", "ì˜í–¥"]
            
            # ì˜ˆìƒ ì˜í–¥ ì¶”ì¶œ
            if "ìƒìŠ¹" in response:
                expected_impact = "ìƒìŠ¹"
            elif "í•˜ë½" in response:
                expected_impact = "í•˜ë½"
            else:
                expected_impact = "ë³´í•©"
            
            # ì§€ì† ì‹œê°„ ì¶”ì¶œ
            if "ì¥ê¸°" in response:
                duration = "ì¥ê¸°"
            elif "ë‹¨ê¸°" in response:
                duration = "ë‹¨ê¸°"
            else:
                duration = "ì¤‘ê¸°"
            
            return {
                "summary": response[:200] + "..." if len(response) > 200 else response,
                "impact_score": impact_score,
                "sentiment": sentiment,
                "sentiment_reason": "í…ìŠ¤íŠ¸ ë¶„ì„ ê¸°ë°˜",
                "keywords": keywords,
                "expected_impact": expected_impact,
                "impact_duration": duration
            }
        except Exception as e:
            logger.error(f"âŒ ê³µì‹œ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "summary": f"{stock_name} ê³µì‹œ ë¶„ì„",
                "impact_score": 0.5,
                "sentiment": "ì¤‘ë¦½",
                "sentiment_reason": "íŒŒì‹± ì‹¤íŒ¨",
                "keywords": ["ê³µì‹œ", "ë¶„ì„", "ì˜í–¥"],
                "expected_impact": "ë³´í•©",
                "impact_duration": "ì¤‘ê¸°"
            }
    
    async def generate_comprehensive_report_and_keywords(self, research_report: str, weekly_market_data: List[Dict]) -> Dict:
        """ì¢…í•© ë³´ê³ ì„œ ë° í‚¤ì›Œë“œ ìƒì„± (OpenAI ì „ìš©)"""
        prompt = f"""
ë‹¹ì‹ ì€ ì£¼ì‹ ì‹œì¥ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ìµœì‹  ë¦¬ì„œì¹˜ ë³´ê³ ì„œì™€ ì¼ì£¼ì¼ì¹˜ ì‹œì¥ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•© ì£¼ê°„ ë¦¬í¬íŠ¸ì™€ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ë¦¬ì„œì¹˜ ë³´ê³ ì„œ:
{research_report}

ì¼ì£¼ì¼ì¹˜ ì‹œì¥ ë°ì´í„°:
{weekly_market_data}

ìš”ì²­ì‚¬í•­:
1. ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ (1500ì ë‚´ì™¸): ë‹¤ìŒ í•­ëª©ì„ ìˆœì„œëŒ€ë¡œ í¬í•¨
   - ì‹œì¥ ì „ë°˜ ìš”ì•½ ë° ì£¼ìš” ì´ìŠˆ
   - íŠ¹ì • ì¢…ëª© ë¶„ì„ (ê¸ì •ì /ë¶€ì •ì  ìš”ì¸, íˆ¬ì ì˜ê²¬)
   - ì£¼ìš” ë‰´ìŠ¤ ë° ê³µì‹œ ë‚´ìš© ìš”ì•½ (ë‚ ì§œë³„ êµ¬ë¶„)
   - ì°¨íŠ¸ ë°ì´í„° ë¶„ì„ (ê°€ê²© ë³€ë™, ê±°ë˜ëŸ‰ ì¶”ì´)
   - í–¥í›„ ì „ë§ ë° íˆ¬ì ì „ëµ ì œì•ˆ

2. í•µì‹¬ í‚¤ì›Œë“œ 10ê°œ: ì¤‘ìš”ë„ê°€ ë†’ì€ ìˆœì„œë¡œ

ì‘ë‹µì„ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "report": "ë¦¬í¬íŠ¸ ë‚´ìš© ì—¬ê¸°ì—",
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", ...]
}}
"""
        
        response = await self.generate_response(prompt, max_tokens=3000)
        if not response:
            return {
                "report": "ì¢…í•© ë³´ê³ ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "keywords": ["ì‹œì¥", "ë¶„ì„", "íˆ¬ì", "ì£¼ì‹", "ì „ë§"]
            }
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                parsed = json.loads(json_str)
                
                return {
                    "report": parsed.get("report", response[:1500]),
                    "keywords": parsed.get("keywords", ["ì‹œì¥", "ë¶„ì„", "íˆ¬ì", "ì£¼ì‹", "ì „ë§"])[:10]
                }
            else:
                # JSONì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ íŒŒì‹±
                return self._parse_report_text(response)
                
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"âš ï¸ ë³´ê³ ì„œ JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ì „í™˜: {e}")
            return self._parse_report_text(response)
    
    def _parse_report_text(self, response: str) -> Dict:
        """ë³´ê³ ì„œ í…ìŠ¤íŠ¸ íŒŒì‹± (JSON ì‹¤íŒ¨ì‹œ fallback)"""
        try:
            # í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
            keywords_match = re.search(r'í‚¤ì›Œë“œ.*?[:ï¼š]\s*(.+?)(?=\n|$)', response, re.MULTILINE)
            if keywords_match:
                keywords_text = keywords_match.group(1)
                keywords = [k.strip().strip('"[]') for k in re.split(r'[,ï¼Œ]', keywords_text)]
                keywords = [k for k in keywords if k][:10]
            else:
                keywords = ["ì‹œì¥", "ë¶„ì„", "íˆ¬ì", "ì£¼ì‹", "ì „ë§", "ì‹¤ì ", "ë‰´ìŠ¤", "ê³µì‹œ", "ë³€ë™", "ë¦¬í¬íŠ¸"]
            
            return {
                "report": response,
                "keywords": keywords
            }
        except Exception as e:
            logger.error(f"âŒ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "report": response[:1500],
                "keywords": ["ì‹œì¥", "ë¶„ì„", "íˆ¬ì", "ì£¼ì‹", "ì „ë§"]
            }
    
    async def analyze_price_movement(self, stock_name: str, price_change: float, volume: int, news_data: List[Dict], disclosure_data: List[Dict]) -> Dict:
        """ì£¼ê°€ ë³€ë™ ì›ì¸ ë¶„ì„"""
        prompt = f"""
{stock_name}ì˜ ì£¼ê°€ê°€ {price_change}% ë³€ë™í•˜ê³  ê±°ë˜ëŸ‰ì´ {volume:,}ì£¼ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.

ê´€ë ¨ ë‰´ìŠ¤: {news_data}
ê´€ë ¨ ê³µì‹œ: {disclosure_data}

ì£¼ê°€ ë³€ë™ì˜ ì£¼ìš” ì›ì¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ì‘ë‹µ í˜•ì‹:
ì£¼ìš”ì›ì¸: [ì£¼ëœ ì›ì¸ ì„¤ëª…]
ì˜í–¥ìˆœìœ„: [ì›ì¸1, ì›ì¸2, ì›ì¸3]
í–¥í›„ì „ë§: [ìƒìŠ¹/í•˜ë½/ë³´í•©]
ì‹ ë¢°ë„: [0.0-1.0]
ë¶„ì„ê·¼ê±°: [íŒë‹¨ ê·¼ê±°]
"""
        
        response = await self.generate_response(prompt, max_tokens=800)
        if not response:
            return self._get_fallback_price_analysis(stock_name, price_change, volume, news_data, disclosure_data)
        
        # ì‘ë‹µ íŒŒì‹±
        try:
            # ì£¼ìš”ì›ì¸ ì¶”ì¶œ
            cause_match = re.search(r'ì£¼ìš”ì›ì¸:\s*(.+?)(?=\n|ì˜í–¥ìˆœìœ„:|$)', response, re.DOTALL)
            main_cause = cause_match.group(1).strip() if cause_match else "ì‹œì¥ ì „ì²´ íë¦„"
            
            # ì˜í–¥ìˆœìœ„ ì¶”ì¶œ
            ranking_match = re.search(r'ì˜í–¥ìˆœìœ„:\s*(.+?)(?=\n|í–¥í›„ì „ë§:|$)', response)
            if ranking_match:
                ranking_text = ranking_match.group(1)
                all_causes = [c.strip() for c in re.split(r'[,ï¼Œ]', ranking_text)]
            else:
                all_causes = [main_cause]
            
            # í–¥í›„ì „ë§ ì¶”ì¶œ
            outlook_match = re.search(r'í–¥í›„ì „ë§:\s*(.+?)(?=\n|ì‹ ë¢°ë„:|$)', response)
            outlook = outlook_match.group(1).strip() if outlook_match else "ë³´í•©"
            
            # ì‹ ë¢°ë„ ì¶”ì¶œ
            confidence_match = re.search(r'ì‹ ë¢°ë„:\s*([0-9.]+)', response)
            confidence = float(confidence_match.group(1)) if confidence_match else 0.7
            
            # ë¶„ì„ê·¼ê±° ì¶”ì¶œ
            reason_match = re.search(r'ë¶„ì„ê·¼ê±°:\s*(.+?)(?=\n|$)', response, re.DOTALL)
            analysis_reason = reason_match.group(1).strip() if reason_match else "ë°ì´í„° ê¸°ë°˜ ë¶„ì„"
            
            return {
                "main_cause": main_cause,
                "all_causes": all_causes[:5],
                "impact_ranking": all_causes[:3],
                "future_outlook": outlook,
                "confidence": min(1.0, max(0.0, confidence)),
                "analysis_reason": analysis_reason,
                "analysis_time": datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"âŒ ì£¼ê°€ ë³€ë™ ë¶„ì„ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._get_fallback_price_analysis(stock_name, price_change, volume, news_data, disclosure_data)
    
    def _get_fallback_price_analysis(self, stock_name: str, price_change: float, volume: int, news_data: List[Dict], disclosure_data: List[Dict]) -> Dict:
        """ì£¼ê°€ ë³€ë™ ë¶„ì„ ì‹¤íŒ¨ ì‹œ fallback"""
        causes = []
        if news_data and len(news_data) > 0:
            causes.append("ë‰´ìŠ¤ ì˜í–¥")
        if disclosure_data and len(disclosure_data) > 0:
            causes.append("ê³µì‹œ ì˜í–¥")
        if volume > 10000000:  # 1ì²œë§Œì£¼ ì´ìƒ
            causes.append("ëŒ€ëŸ‰ ê±°ë˜")
        if abs(price_change) > 5:
            causes.append("ê¸‰ê²©í•œ ë³€ë™")
        if abs(price_change) > 10:
            causes.append("ë§¤ìš° ê¸‰ê²©í•œ ë³€ë™")
        
        return {
            "main_cause": causes[0] if causes else "ì‹œì¥ ì „ì²´ íë¦„",
            "all_causes": causes,
            "impact_ranking": causes[:3],
            "future_outlook": "ìƒìŠ¹" if price_change > 0 else "í•˜ë½" if price_change < 0 else "ë³´í•©",
            "confidence": 0.6,
            "analysis_reason": "ê¸°ë³¸ ì§€í‘œ ê¸°ë°˜ ë¶„ì„",
            "analysis_time": datetime.now().isoformat()
        }
    
    async def generate_weekly_report(self, stock_name: str, weekly_data: Dict) -> Dict:
        """ì£¼ê°„ ë³´ê³ ì„œ ìƒì„±"""
        prompt = f"""
{stock_name}ì˜ ì£¼ê°„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íˆ¬ìììš© ì£¼ê°„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì£¼ê°„ ë°ì´í„°: {weekly_data}

ë³´ê³ ì„œ í˜•ì‹:
ì£¼ìš”ì´ìŠˆìš”ì•½: [ì´ë²ˆ ì£¼ í•µì‹¬ ì´ìŠˆë“¤]
ì£¼ê°€ë³€ë™ë¶„ì„: [ì£¼ê°€ ë³€ë™ ì›ì¸ê³¼ íŒ¨í„´ ë¶„ì„]
ë‹¤ìŒì£¼ì „ë§: [ë‹¤ìŒ ì£¼ ì˜ˆìƒ ì‹œë‚˜ë¦¬ì˜¤]
ëª¨ë‹ˆí„°ë§í‚¤ì›Œë“œ: [ì£¼ìš” ê´€ì°° í‚¤ì›Œë“œ 5ê°œ]
íˆ¬ìì „ëµ: [ë‹¨ê¸° íˆ¬ì ì „ëµ ì œì•ˆ]
"""
        
        response = await self.generate_response(prompt, max_tokens=1200)
        if not response:
            return self._get_fallback_weekly_report(stock_name, weekly_data)
        
        # ì‘ë‹µ íŒŒì‹±
        try:
            # ì£¼ìš”ì´ìŠˆìš”ì•½ ì¶”ì¶œ
            issues_match = re.search(r'ì£¼ìš”ì´ìŠˆìš”ì•½:\s*(.+?)(?=\n|ì£¼ê°€ë³€ë™ë¶„ì„:|$)', response, re.DOTALL)
            if issues_match:
                issues_text = issues_match.group(1).strip()
                key_issues = [issue.strip() for issue in issues_text.split('\n') if issue.strip()]
            else:
                key_issues = [f"{stock_name} ì£¼ê°„ ì£¼ìš” ì´ìŠˆ"]
            
            # ì£¼ê°€ë³€ë™ë¶„ì„ ì¶”ì¶œ
            price_match = re.search(r'ì£¼ê°€ë³€ë™ë¶„ì„:\s*(.+?)(?=\n|ë‹¤ìŒì£¼ì „ë§:|$)', response, re.DOTALL)
            price_analysis = price_match.group(1).strip() if price_match else f"{stock_name} ì£¼ê°€ ë¶„ì„"
            
            # ë‹¤ìŒì£¼ì „ë§ ì¶”ì¶œ
            outlook_match = re.search(r'ë‹¤ìŒì£¼ì „ë§:\s*(.+?)(?=\n|ëª¨ë‹ˆí„°ë§í‚¤ì›Œë“œ:|$)', response, re.DOTALL)
            next_week_outlook = outlook_match.group(1).strip() if outlook_match else "ë³´í•© ì „ë§"
            
            # ëª¨ë‹ˆí„°ë§í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords_match = re.search(r'ëª¨ë‹ˆí„°ë§í‚¤ì›Œë“œ:\s*(.+?)(?=\n|íˆ¬ìì „ëµ:|$)', response)
            if keywords_match:
                keywords_text = keywords_match.group(1)
                keywords = [k.strip() for k in re.split(r'[,ï¼Œ]', keywords_text)]
                keywords = [k for k in keywords if k][:5]
            else:
                keywords = [stock_name, "ì£¼ê°€", "ë¶„ì„", "ì‹œì¥", "íˆ¬ì"]
            
            # íˆ¬ìì „ëµ ì¶”ì¶œ
            strategy_match = re.search(r'íˆ¬ìì „ëµ:\s*(.+?)(?=\n|$)', response, re.DOTALL)
            investment_strategy = strategy_match.group(1).strip() if strategy_match else "ì‹ ì¤‘í•œ ê´€ë§"
            
            return {
                "summary": f"{stock_name} ì£¼ê°„ ë¶„ì„ ë³´ê³ ì„œ",
                "key_issues": key_issues[:5],
                "price_analysis": price_analysis,
                "next_week_outlook": next_week_outlook,
                "monitoring_keywords": keywords,
                "investment_strategy": investment_strategy,
                "generated_time": datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"âŒ ì£¼ê°„ ë³´ê³ ì„œ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._get_fallback_weekly_report(stock_name, weekly_data)
    
    def _get_fallback_weekly_report(self, stock_name: str, weekly_data: Dict) -> Dict:
        """ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨ ì‹œ fallback"""
        news_count = len(weekly_data.get('news', []))
        disclosure_count = len(weekly_data.get('disclosures', []))
        price_change = weekly_data.get('price_change', 0)
        
        return {
            "summary": f"{stock_name} ì£¼ê°„ ë¶„ì„ ë³´ê³ ì„œ",
            "key_issues": [
                f"ì´ë²ˆ ì£¼ ë‰´ìŠ¤ {news_count}ê±´ ë°œìƒ",
                f"ê³µì‹œ {disclosure_count}ê±´ ê³µê°œ",
                f"ì£¼ê°€ {price_change:+.2f}% ë³€ë™ ê¸°ë¡"
            ],
            "price_analysis": f"ì£¼ê°€ê°€ ì „ì£¼ ëŒ€ë¹„ {price_change:+.2f}% {'ìƒìŠ¹' if price_change > 0 else 'í•˜ë½' if price_change < 0 else 'ë³´í•©'}í–ˆìŠµë‹ˆë‹¤.",
            "next_week_outlook": "ìƒìŠ¹ ê¸°ëŒ€" if price_change > 0 else "í•˜ë½ ìš°ë ¤" if price_change < 0 else "ë³´í•© ì „ë§",
            "monitoring_keywords": [stock_name, "ì£¼ê°€", "ì‹œì¥", "ë¶„ì„", "íˆ¬ì"],
            "investment_strategy": "ì‹œì¥ ìƒí™©ì„ ì§€ì¼œë³´ë©° ì‹ ì¤‘í•œ íˆ¬ì í•„ìš”",
            "generated_time": datetime.now().isoformat()
        }
    
    async def __aenter__(self):
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.close()


# ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
openai_client = OpenAIClient()


async def get_openai_client() -> OpenAIClient:
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    return openai_client