"""
ì£¼ê°„ ë³´ê³ ì„œ ì„œë¹„ìŠ¤ (Report Service)
- ë¦¬ì„œì¹˜ ë³´ê³ ì„œ í¬ë¡¤ë§ (ë„¤ì´ë²„ ê¸ˆìœµ PDF)
- ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
- í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì €ì¥
- ë§¤ì£¼ ì¼ìš”ì¼ ì €ë… ì‹¤í–‰
"""
import nest_asyncio
import asyncio
import json
import logging
import requests
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union, Any, Tuple
from pathlib import Path
import sys
import PyPDF2
from textwrap import wrap
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from io import BytesIO
from reportlab.lib.pagesizes import letter
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from research_crawler import ResearchCrawler
from webdriver_manager.chrome import ChromeDriverManager
import hashlib
import time
import schedule
import os

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from shared.database.mysql_client import get_mysql_client
from shared.database.vector_db import VectorDBClient
from shared.llm.llm_manager import llm_manager
from shared.apis.telegram_api import TelegramBotClient
from config.env_local import get_config
from shared.user_config.user_config_manager import user_config_manager
from shared.service_config.user_config_loader import get_config_loader

# FastAPI ì¶”ê°€
from fastapi import FastAPI, HTTPException, BackgroundTasks, Request
import uvicorn

app = FastAPI(title="Weekly Report Service", version="1.0.0")

class ReportService:
    """ì£¼ê°„ ë³´ê³ ì„œ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self):
        # ê°œë°œì ê¸°ë³¸ ì„¤ì • ë¡œë“œ
        self.config = get_config()
        
        # ì‚¬ìš©ì ì„¤ì • ê´€ë¦¬ì ì´ˆê¸°í™”
        self.user_config_manager = user_config_manager
        self.current_user_id = os.environ.get('HYPERASSET_USER_ID', "1")  # ğŸ”¥ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì‚¬ìš©ì ID ì½ê¸°
        self.stocks_config = {}  # ì‚¬ìš©ìë³„ ì¢…ëª© ì„¤ì • (MySQLì—ì„œ ë®ì–´ì“°ê¸°)
        
        # ì‚¬ìš©ìë³„ ê°œì¸í™” ì„¤ì • ë¡œë”
        self.user_config_loader = None  # ë¹„ë™ê¸°ë¡œ ì´ˆê¸°í™”ë¨
        self.personalized_configs = {}  # ì‚¬ìš©ìë³„ ê°œì¸í™” ì„¤ì • ìºì‹œ
        
        self.mysql_client = get_mysql_client()
        # ChromaDB ëŒ€ì‹œë³´ë“œì™€ ë™ì¼í•œ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ë„ë¡ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        news_service_chroma_path = os.path.join(project_root, "services", "news_service", "data", "chroma")
        os.environ["CHROMADB_PERSIST_DIRECTORY"] = news_service_chroma_path
        self.vector_db = VectorDBClient()
        self.llm_manager = llm_manager
        self.telegram_bot = TelegramBotClient()
        self.research_crawler = ResearchCrawler()

        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        )
        self.logger = logging.getLogger(__name__)
        
        # ì‚¬ìš©ìë³„ ì„¤ì • ë¡œë“œ (MySQLì—ì„œ stock_codeë§Œ ë®ì–´ì“°ê¸°)
        asyncio.create_task(self._load_user_settings())
        
    async def _load_user_settings(self):
        """ì‚¬ìš©ìë³„ ì„¤ì • ë¡œë“œ (User Config Managerì—ì„œ ì¤‘ì•™ ì§‘ì¤‘ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°)"""
        try:
            user_config = await self.user_config_manager.get_user_config(self.current_user_id)
            
            # ì‚¬ìš©ì ì¢…ëª© ì„¤ì •ìœ¼ë¡œ ë®ì–´ì“°ê¸°
            self.stocks_config = {}
            for stock in user_config.get("stocks", []):
                if stock.get("enabled", True):
                    self.stocks_config[stock["stock_code"]] = {
                        "name": stock["stock_name"],
                        "enabled": True
                    }
            
            self.logger.info(f"âœ… ì‚¬ìš©ì ì¢…ëª© ì„¤ì • ë¡œë“œ ì™„ë£Œ: {len(self.stocks_config)}ê°œ ì¢…ëª©")
            
        except Exception as e:
            self.logger.error(f"âŒ ì‚¬ìš©ì ì„¤ì • ë¡œë“œ ì‹¤íŒ¨ (ê¸°ë³¸ê°’ ìœ ì§€): {e}")
            # ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì¢…ëª© ì„¤ì •
            self.stocks_config = {
                "005930": {"name": "ì‚¼ì„±ì „ì", "enabled": True},
                "000660": {"name": "SKí•˜ì´ë‹‰ìŠ¤", "enabled": True}
            }
    
    async def set_user_id(self, user_id):
        """ì‚¬ìš©ì ID ì„¤ì • ë° ì„¤ì • ì¬ë¡œë“œ"""
        try:
            self.current_user_id = user_id
            await self._load_user_settings()
            self.logger.info(f"âœ… ì‚¬ìš©ì ID ì„¤ì • ë° ì„¤ì • ì¬ë¡œë“œ ì™„ë£Œ: {user_id}")
        except Exception as e:
            self.logger.error(f"âŒ ì‚¬ìš©ì ID ì„¤ì • ì‹¤íŒ¨: {e}")
            raise

    async def collect_weekly_market_data(self, stock_code: str) -> Dict: ############################################ì™„ë£Œ 
        """
        ChromaDBì—ì„œ ì§€ë‚œ 7ì¼ê°„ì˜ ë¦¬ì„œì¹˜ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ì™€
        ê³µì‹œ DBì—ì„œ ì§€ë‚œ 7ì¼ê°„ì˜ ê³µì‹œ ìš”ì•½ì„ ìˆ˜ì§‘í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        weekly_news_by_date: Dict[str, str] = {}
        weekly_disclosure_by_date: Dict[str, str] = {}
        weekly_chart_data: List[Dict[str, Any]] = []

        # 1. ì§€ë‚œ 7ì¼ê°„ì˜ ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
        today = datetime.now()
        seven_days_ago = today - timedelta(days=7)

        today_str = today.strftime('%Y-%m-%d')
        seven_days_ago_str = seven_days_ago.strftime('%Y-%m-%d')
        
        seven_days_ago_str_iso = seven_days_ago.strftime('%Y-%m-%dT%H:%M:%S')
        today_str_iso = today.strftime('%Y-%m-%dT%H:%M:%S')

        self.logger.info(f"Collecting weekly market data for {stock_code} from {seven_days_ago_str} to {today_str}...")

        # 2. ChromaDBì—ì„œ ë¦¬ì„œì¹˜ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ ì¡°íšŒ (ë‰´ìŠ¤/ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¡œ ê°„ì£¼)
        try:
            # self.vector_dbì˜ collections ì†ì„±ì„ í†µí•´ íŠ¹ì • ì»¬ë ‰ì…˜ì„ ì¿¼ë¦¬í•©ë‹ˆë‹¤.
            # 'weekly_reports' ì»¬ë ‰ì…˜ì´ ë©”íƒ€ë°ì´í„°ì— 'publication_date' ë° 'stock_code'ë¥¼ í¬í•¨í•œ
            # ë¦¬ì„œì¹˜ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
            self.logger.info(f"DEBUG: ChromaDB ì¿¼ë¦¬ ì‹œì‘. stock_code: {stock_code}")
            chroma_results = self.vector_db.collections["high_impact_news"].query(
                query_texts=[""], # ë©”íƒ€ë°ì´í„° í•„í„°ë§ì„ ìœ„í•œ ë¹ˆ ì¿¼ë¦¬ í…ìŠ¤íŠ¸
                n_results=100, # ê²€ìƒ‰í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜
                where={
                    "stock_code": "006800"
                },
                include=['documents', 'metadatas'] # ë¬¸ì„œ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ê°€ì ¸ì˜¤ë„ë¡ ëª…ì‹œ
            )
            self.logger.info(f"DEBUG: ChromaDB ì¿¼ë¦¬ ê²°ê³¼ (raw): {chroma_results}")
            if chroma_results and chroma_results.get('documents') and chroma_results.get('metadatas'):
                # ChromaDBì˜ documentsì™€ metadatasëŠ” ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì²« ë²ˆì§¸ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸
                if chroma_results['documents'] and chroma_results['documents'][0]:
                    self.logger.info(f"DEBUG: ChromaDBì—ì„œ {len(chroma_results['documents'][0])}ê°œì˜ ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
                    # ChromaDBì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
                    for i, doc_content in enumerate(chroma_results['documents'][0]):
                        metadata = chroma_results['metadatas'][0][i]
                        publication_date_str = metadata.get('publication_date')
                        self.logger.info(f"DEBUG: ë¬¸ì„œ {i} - publication_date_str: {publication_date_str}, metadata: {metadata}")
                        
                        if publication_date_str:
                            try:
                                # ISO í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜
                                # publication_dateê°€ datetime.date ê°ì²´ì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ, fromisoformat ëŒ€ì‹  strptime ì‚¬ìš©
                                publication_date = datetime.strptime(publication_date_str.split('T')[0], '%Y-%m-%d').date()
                                self.logger.info(f"DEBUG: íŒŒì‹±ëœ publication_date: {publication_date}")
                                self.logger.info(f"DEBUG: ë‚ ì§œ ë²”ìœ„: {seven_days_ago.date()} <= {publication_date} <= {today.date()}")
                                # 7ì¼ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
                                if seven_days_ago.date() <= publication_date <= today.date():
                                    self.logger.info(f"DEBUG: ë‚ ì§œ ì¡°ê±´ ë§Œì¡±: {publication_date_str}")
                                    if publication_date_str not in weekly_news_by_date:
                                        weekly_news_by_date[publication_date_str] = ""
                                    weekly_news_by_date[publication_date_str] += doc_content + " "
                                    self.logger.info(f"DEBUG: weekly_news_by_date ì—…ë°ì´íŠ¸ë¨. í˜„ì¬ ê¸¸ì´: {len(weekly_news_by_date)}")
                                else:
                                    self.logger.info(f"DEBUG: ë‚ ì§œ ì¡°ê±´ ë¶ˆë§Œì¡±: {publication_date_str}")
                            except ValueError:
                                self.logger.warning(f"ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ ë˜ëŠ” íŒŒì‹± ì˜¤ë¥˜: {publication_date_str}")
                        else:
                            self.logger.info(f"DEBUG: publication_date_strì´ ì—†ìŠµë‹ˆë‹¤.")

                self.logger.info(f"ChromaDB: ì§€ë‚œ 7ì¼ê°„ {stock_code}ì— ëŒ€í•œ ë¦¬ì„œì¹˜ ë³´ê³ ì„œ {len(weekly_news_by_date)}ì¼ì¹˜ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            else:
                self.logger.info(f"ChromaDB: ì§€ë‚œ 7ì¼ê°„ {stock_code}ì— ëŒ€í•œ ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (chroma_results ë¹„ì–´ìˆìŒ)")

        except Exception as e:
            self.logger.error(f"ChromaDB ë¦¬ì„œì¹˜ ë³´ê³ ì„œ ì¿¼ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


        # 3. ê³µì‹œ DBì—ì„œ ê³µì‹œ ìš”ì•½ ì¡°íšŒ
        try:
            # ê³µì‹œ ë°ì´í„°ê°€ self.mysql_clientë¥¼ í†µí•´ ì ‘ê·¼ ê°€ëŠ¥í•œ MySQL í…Œì´ë¸”ì— ìˆê³ ,
            # 'rcept_dt' (ì ‘ìˆ˜ì¼) ë° 'summary' ì»¬ëŸ¼ì„ ê°€ì§€ê³  ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
            disclosure_query = """
            SELECT rcept_dt, summary FROM disclosure_history
            WHERE stock_code = %s AND rcept_dt >= %s AND rcept_dt <= %s
            """
            disclosure_data = await self.mysql_client.fetch_all_async(
                disclosure_query, (stock_code, seven_days_ago_str, today_str)
            )
            if disclosure_data:
                for row in disclosure_data:
                    rcept_dt = row.get('rcept_dt')
                    summary = row.get('summary')
                    if rcept_dt and summary:
                        rcept_dt_str = rcept_dt.strftime('%Y-%m-%d') if isinstance(rcept_dt, datetime) else str(rcept_dt)
                        if rcept_dt_str not in weekly_disclosure_by_date:
                            weekly_disclosure_by_date[rcept_dt_str] = ""
                        weekly_disclosure_by_date[rcept_dt_str] += summary + " "

                self.logger.info(f"ê³µì‹œ DB: {stock_code}ì— ëŒ€í•œ ê³µì‹œ ìš”ì•½ {len(weekly_disclosure_by_date)}ì¼ì¹˜ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            else:
                self.logger.info(f"ê³µì‹œ DB: ì§€ë‚œ 7ì¼ê°„ {stock_code}ì— ëŒ€í•œ ê³µì‹œ ìš”ì•½ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            self.logger.error(f"ê³µì‹œ DB ìš”ì•½ ì¿¼ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # 4. ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘
        try:
            chart_query = """
            SELECT date, close_price, volume FROM chart_analysis_results
            WHERE stock_code = %s AND date >= %s AND date <= %s
            ORDER BY date ASC
            """
            chart_results = await self.mysql_client.fetch_all_async(
                chart_query, (stock_code, seven_days_ago_str, today_str)
            )
            if chart_results:
                for row in chart_results:
                    chart_date_str = row['date'].strftime('%Y-%m-%d') if isinstance(row['date'], datetime) else str(row['date'])
                    weekly_chart_data.append({
                        "date": chart_date_str,
                        "close_price": float(row['close_price']),
                        "volume": int(row['volume'])
                    })
                self.logger.info(f"ì°¨íŠ¸ DB: {stock_code}ì— ëŒ€í•œ ì°¨íŠ¸ ë°ì´í„° {len(weekly_chart_data)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            else:
                self.logger.info(f"ì°¨íŠ¸ DB: ì§€ë‚œ 7ì¼ê°„ {stock_code}ì— ëŒ€í•œ ì°¨íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            self.logger.error(f"ì°¨íŠ¸ DB ì¿¼ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ìš”ì²­ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        result_list = []

        if weekly_news_by_date:
            result_list.append({"impact_news": weekly_news_by_date})
        if weekly_disclosure_by_date:
            result_list.append({"disclosure": weekly_disclosure_by_date})
        if weekly_chart_data:
            result_list.append({"chart": weekly_chart_data})

        return result_list
    
    
   
   
    def _format_weekly_market_data_for_llm(self, weekly_market_data: List[Dict]) -> str:
        formatted_text = []
        for item in weekly_market_data:
            if "impact_news" in item:
                formatted_text.append("### ì£¼ê°„ ë‰´ìŠ¤:")
                for date_str, news_content in item["impact_news"].items():
                    formatted_text.append(f"- {date_str}: {news_content.strip()}")
            elif "disclosure" in item:
                formatted_text.append("### ì£¼ê°„ ê³µì‹œ:")
                for date_str, disclosure_content in item["disclosure"].items():
                    formatted_text.append(f"- {date_str}: {disclosure_content.strip()}")
            elif "chart" in item:
                formatted_text.append("### ì£¼ê°„ ì°¨íŠ¸ ë°ì´í„°:")
                for chart_entry in item["chart"]:
                    formatted_text.append(f"- ë‚ ì§œ: {chart_entry['date']}, ì¢…ê°€: {chart_entry['close_price']}, ê±°ë˜ëŸ‰: {chart_entry['volume']}")
        return "\n".join(formatted_text)





    def _generate_pdf_report(self, report_text: str, stock_code: str) -> BytesIO:
        """ë¦¬í¬íŠ¸ í…ìŠ¤íŠ¸ë¥¼ PDFë¡œ ë©”ëª¨ë¦¬ì— ìƒì„±"""
        try:
            buffer = BytesIO()
            c = canvas.Canvas(buffer, pagesize=letter)

            try:
                # static/fonts/NanumGothic.ttf ê²½ë¡œì—ì„œ í°íŠ¸ ë¡œë“œ
                font_path = Path(__file__).parent.parent.parent / "static" / "fonts" / "NanumGothic.ttf"
                if not font_path.exists():
                    raise FileNotFoundError(f"í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {font_path}")
                pdfmetrics.registerFont(TTFont('NanumGothic', str(font_path)))
                c.setFont('NanumGothic', 12)
            except Exception as e:
                self.logger.warning(f"ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}. ê¸°ë³¸ í°íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                c.setFont('Helvetica', 12)

            textobject = c.beginText()
            textobject.setTextOrigin(50, 750)
            textobject.setLeading(14)

            wrapped_lines = []
            for line in report_text.split('\n'):
                # ê¸´ ì¤„ì€ ì˜ë¼ì„œ wrap

                # âœ… ë¬¸ë‹¨ êµ¬ë¶„ìš©: # ë¡œ ì‹œì‘í•˜ë©´ ë¹ˆ ì¤„ ì¶”ê°€
                if line.startswith("#"):
                    wrapped_lines.append("")  # ë¬¸ë‹¨ ê°„ ë¹ˆ ì¤„
                    line = "â€¢ " + line.lstrip("#").strip()  # ë³´ê¸° ì¢‹ê²Œ ë§ˆí¬ ë‹¬ê¸° (â˜…, â€¢ ë“± ì·¨í–¥)
                wrapped = wrap(line, width=50)  # widthëŠ” ê¸€ì ìˆ˜ ê¸°ì¤€
                wrapped_lines.extend(wrapped if wrapped else [""])  # ë¹ˆ ì¤„ë„ ìœ ì§€

            for line in wrapped_lines:
                textobject.textLine(line)
            c.drawText(textobject)
            c.save()
            buffer.seek(0)
            return buffer

        except Exception as e:
            self.logger.error(f"PDF ìƒì„± ì‹¤íŒ¨: {e}")
            return BytesIO()
    async def send_weekly_report_telegram(self, stock_code: str, pdf_buffer: BytesIO, keywords: List[str]):
        """PDF BytesIO ê°ì²´ë¥¼ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì „ì†¡"""
        try:
            message = f"""
                ğŸ“¢ ì£¼ê°„ ë¦¬í¬íŠ¸ê°€ ë„ì°©í–ˆì–´ìš”!

                ğŸ“… **ê¸°ê°„**: {datetime.now().strftime('%Y-%m-%d')} ê¸°ì¤€ ì¼ì£¼ì¼  
                ğŸ¢ **ì¢…ëª©**: {stock_code}  

                ì¼ì£¼ì¼ê°„ ì°¨íŠ¸, ê³µì‹œ, ì£¼ìš” ë‰´ìŠ¤ë¥¼ ì¢…í•©í•´ì„œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í–ˆì–´ìš”!  
                ìì„¸í•œ ë‚´ìš©ì€ ì²¨ë¶€ëœ PDFë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.

                ğŸ” ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(keywords)}
                        """

            # íŒŒì¼ ì´ë¦„ì€ í…”ë ˆê·¸ë¨ì— í‘œì‹œë§Œ ë¨
            file_name = f"weekly_report_{stock_code}.pdf"

            success = self.telegram_bot.send_document_from_buffer(document=pdf_buffer, filename=file_name, caption=message)

            # ìµœê·¼ ì•ŒëŒ ë©”ì‹œì§€ ì €ì¥
            if success:
                await save_latest_signal(message)
            
            if success:
                self.logger.info(f"ì£¼ê°„ ë³´ê³ ì„œ í…”ë ˆê·¸ë¨ ì „ì†¡ ì™„ë£Œ: {stock_code}")
            else:
                self.logger.error(f"ì£¼ê°„ ë³´ê³ ì„œ í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {stock_code}")
                

        except Exception as e:
            self.logger.error(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

    async def save_keywords_to_vector_db(self, stock_code: str, keywords: List[str]):
        """ì£¼ì–´ì§„ í‚¤ì›Œë“œë¥¼ ë²¡í„° DBì˜ 'weekly_keywords' ì»¬ë ‰ì…˜ì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            if not keywords:
                self.logger.info(f"{stock_code}ì— ëŒ€í•œ ì €ì¥í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            self.logger.info(f"{stock_code}ì— ëŒ€í•œ í‚¤ì›Œë“œë¥¼ ë²¡í„° DBì— ì €ì¥ ì‹œì‘...")

            # 1. ë‚ ì§œ ë° ì‹œê°„ ì •ë³´ ìƒì„±
            now = datetime.now()
            week_start = now - timedelta(days=7)
            week_start_str = week_start.strftime('%Y-%m-%dT00:00:00')

            # 2. ì¤‘ë³µ ì²´í¬
            existing_keywords = self.vector_db.collections["keywords"].get(
                where={
                    "$and": [
                        {"stock_code": {"$eq": stock_code}},
                        {"week_start": {"$eq": week_start_str}}
                    ]
                },
                limit=1
            )

            if existing_keywords and len(existing_keywords['ids']) > 0:
                self.logger.warning(f"ì¤‘ë³µ í‚¤ì›Œë“œ ë°œê²¬ - ì €ì¥ ê±´ë„ˆëœ€: {stock_code} {week_start_str}")
                return

            # 3. ì¢…ëª© ì´ë¦„ ì¡°íšŒ
            try:
                with open(project_root / "config" / "stocks.json", "r", encoding="utf-8") as f:
                    stocks_config = json.load(f)
                stock_name = stocks_config.get(stock_code, {}).get("name", "Unknown")
            except Exception as e:
                self.logger.error(f"stocks.json íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                stock_name = "Unknown"

            # 4. ê³ ìœ  ID ìƒì„±
            timestamp = now.strftime('%Y%m%d_%H%M%S')
            microseconds = int(time.time() * 1000000) % 1000000
            keywords_hash = hashlib.md5(",".join(keywords).encode('utf-8')).hexdigest()[:6]
            keyword_id = f"keyword_{stock_code}_{timestamp}_{microseconds:06d}_{keywords_hash}"

            # 5. ë©”íƒ€ë°ì´í„° êµ¬ì„±
            metadata = {
                "stock_code": stock_code,
                "stock_name": stock_name,
                "keywords_json": json.dumps(keywords, ensure_ascii=False),
                "keywords_text": ", ".join(keywords),
                "keywords_count": len(keywords),
                "importance_scores_json": json.dumps([]),  # null ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸ì˜ JSON ë¬¸ìì—´
                "week_start": week_start_str,
                "week_end": now.strftime('%Y-%m-%dT00:00:00'),
                "type": "keywords",
                "created_at": now.isoformat(),
            }

            # 6. ë²¡í„° DBì— ì €ì¥í•  ë¬¸ì„œ(document) ìƒì„± (ì„ë² ë”©ë  ì‹¤ì œ í…ìŠ¤íŠ¸)
            document_for_embedding = ", ".join(keywords)

            # 7. ë²¡í„° DBì— ë°ì´í„° ì¶”ê°€
            self.vector_db.add_documents(
                collection_name="keywords",
                documents=[document_for_embedding],
                metadatas=[metadata],
                ids=[keyword_id]
            )

            self.logger.info(f"{stock_code}ì— ëŒ€í•œ í‚¤ì›Œë“œë¥¼ ë²¡í„° DBì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤. (ID: {keyword_id})")

        except Exception as e:
            self.logger.error(f"ë²¡í„° DBì— í‚¤ì›Œë“œ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _parse_llm_response(self, response_text: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ JSON ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì˜¤ë¥˜ì— ëŒ€í•´ ìë™ ìˆ˜ì •ì„ ì‹œë„í•˜ê³ , ë¶€ë¶„ì ì¸ í‚¤ ë§¤ì¹­ì„ ì§€ì›í•©ë‹ˆë‹¤."""
        
        def get_partial_key_value(d: dict, keyword: str):
            """ì‚¬ì „ì—ì„œ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” í‚¤ì˜ ê°’ì„ ì°¾ìŠµë‹ˆë‹¤."""
            for k, v in d.items():
                if keyword in k:
                    return v
            return None

        if not response_text:
            self.logger.error("LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return {"report": "LLM ì‘ë‹µ ì—†ìŒ", "keywords": []}

        try:
            # ë¶ˆí•„ìš”í•œ ì œì–´ ë¬¸ì ì œê±°
            cleaned_text = re.sub(r'[\x00-\x1F\x7F]', '', response_text.strip())
            
            # JSON ê°ì²´ë§Œ ì¶”ì¶œ (ì˜ˆ: ```json ... ``` íŒ¨í„´)
            match = re.search(r'```json\n(.*?)```', cleaned_text, re.DOTALL)
            if match:
                json_str = match.group(1)
            else:
                # ê¸°ì¡´ ë¡œì§ì—ì„œ ìˆœìˆ˜ JSON ê°ì²´ ì¶”ì¶œ ë¡œì§ì´ ìˆì—ˆìœ¼ë¯€ë¡œ ìœ ì§€
                match = re.search(r'\{.*\}', cleaned_text, re.DOTALL)
                if match:
                    json_str = match.group(0)
                else:
                    json_str = cleaned_text # ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ì´ë‚˜ ìˆœìˆ˜ JSONì´ ì•„ë‹ˆë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©

            parsed_json = json.loads(json_str)
            
        except json.JSONDecodeError as e:
            self.logger.warning(f"JSON íŒŒì‹± 1ì°¨ ì‹¤íŒ¨: {e}. ìë™ ìˆ˜ì •ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            # ìë™ ìˆ˜ì •: ëˆ„ë½ëœ ì‰¼í‘œ ì¶”ê°€ ( "key": "value" "key2": ... -> "key": "value", "key2": ... )
            # ì´ìŠ¤ì¼€ì´í”„ëœ ë”°ì˜´í‘œê°€ ì•„ë‹Œ ë”°ì˜´í‘œ ë’¤ì— ë‹¤ë¥¸ ë”°ì˜´í‘œê°€ ì˜¤ëŠ” ê²½ìš°, ê·¸ ì‚¬ì´ì— ì‰¼í‘œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
            fixed_text = re.sub(r'(?<!\\)"\s*\n*\s*(?<!\\)"', r'",\n"', cleaned_text)
            
            try:
                # 2ì°¨ íŒŒì‹± ì‹œë„
                parsed_json = json.loads(fixed_text)
                self.logger.info("âœ… JSON ìë™ ìˆ˜ì • ë° íŒŒì‹± ì„±ê³µ")
            except json.JSONDecodeError as e2:
                self.logger.error(f"âŒ JSON ìë™ ìˆ˜ì • í›„ì—ë„ íŒŒì‹± ì‹¤íŒ¨: {e2}")
                self.logger.error(f"ì›ë³¸ ì‘ë‹µ: {response_text}")
                return {"report": f"LLM ì‘ë‹µ íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {e2}", "keywords": []}
        except Exception as e:
            self.logger.error(f"LLM ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
            return {"report": f"LLM ì‘ë‹µ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", "keywords": []}

        # ë¶€ë¶„ í‚¤ ë§¤ì¹­ì„ ì‚¬ìš©í•˜ì—¬ ê°’ ì¶”ì¶œ
        report = get_partial_key_value(parsed_json, "report")
        keywords = get_partial_key_value(parsed_json, "keyword")

        return {
            "report": report if report is not None else "ë¦¬í¬íŠ¸ ë‚´ìš© ì—†ìŒ",
            "keywords": keywords if keywords is not None else []
        }

    async def process_weekly_report(self, stock_code: str):
        """ì£¼ê°„ ë³´ê³ ì„œ ì²˜ë¦¬"""
        

        try:
            self.logger.info(f"ì£¼ê°„ ë³´ê³ ì„œ ì²˜ë¦¬ ì‹œì‘: {stock_code}")

            # 1. ë¦¬ì„œì¹˜ ë³´ê³ ì„œ í¬ë¡¤ë§
            research_report = await self.research_crawler.get_preprocessed_text_for_stock(stock_code) #ë¦¬ì„œì¹˜ text ë°˜í™˜

            # 2. ë‰´ìŠ¤, ê³µì‹œ ,ì°¨íŠ¸ ì¼ì£¼ì¼ê°„ ë°ì´í„° ìˆ˜ì§‘ list í˜•íƒœë¡œ ë°˜í™˜ë¨
            
            weekly_market_data = await self.collect_weekly_market_data(stock_code) 
            
            
            # 3. ì¢…í•©ë³´ê³ ì„œ ë° í‚¤ì›Œë“œ ìƒì„± dict í˜•ì‹ìœ¼ë¡œ ë°›ê¸°
            weekly_market_data = self._format_weekly_market_data_for_llm(weekly_market_data) # weekly_market_dataë¥¼ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
            
            # ì¢…í•© ë³´ê³ ì„œ ë° í‚¤ì›Œë“œ ìƒì„± (ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
            prompt = f"""
            ğŸ“Œìµœì‹  ë¦¬ì„œì¹˜ ë³´ê³ ì„œì™€ ì¼ì£¼ì¼ì¹˜ ë‰´ìŠ¤, ê³µì‹œ, ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë³´ê³  ë¶„ì„í•˜ì—¬ ìµœëŒ€í•œ ìì„¸í•˜ê²Œ ì£¼ê°„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì‹œì˜¤.
            ë³´ê³ ì„œì—ëŠ” ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
            
            ğŸ“Œ ë‹¤ìŒ í•­ëª©ì„ ìˆœì„œëŒ€ë¡œ í¬í•¨í•˜ì‹œì˜¤. **ê° í•­ëª©ì€ ë°˜ë“œì‹œ ìƒˆë¡œìš´ ì¤„ì— ì‹œì‘í•˜ë©°, ë¬¸ë‹¨ ì‹œì‘ì„ '#(ë°˜ë“œì‹œ # í•˜ë‚˜)'ë¡œ í‘œì‹œ**í•˜ì‹œì˜¤:
            #ì‹œì¥ ì „ë°˜ì— ëŒ€í•œ ìš”ì•½ ë° ì£¼ìš” ì´ìŠˆ:
            #íŠ¹ì • ì¢…ëª©ì— ëŒ€í•œ ë¶„ì„ (ê¸ì •ì /ë¶€ì •ì  ìš”ì¸, íˆ¬ì ì˜ê²¬ ë“±):
            #ì£¼ìš” ë‰´ìŠ¤ ë° ê³µì‹œ ë‚´ìš© ìš”ì•½ (ë‚ ì§œë³„ êµ¬ë¶„):
            #ì°¨íŠ¸ ë°ì´í„° ë¶„ì„ (ê°€ê²© ë³€ë™, ê±°ë˜ëŸ‰ ì¶”ì´ ë“±):
            #í–¥í›„ ì „ë§ ë° íˆ¬ì ì „ëµ ì œì•ˆ:
            #ë³´ê³ ì„œì˜ í•µì‹¬ í‚¤ì›Œë“œ (ë¬¸ë‹¨ ë§¨ ë§ˆì§€ë§‰ì— í‘œì‹œ):

            ---
            ìµœì‹  ë¦¬ì„œì¹˜ ë³´ê³ ì„œ:
            {research_report}

            ---
            ì¼ì£¼ì¼ì¹˜ ì‹œì¥ ë°ì´í„°:
            {weekly_market_data}

            ---
            **ì‘ë‹µ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•íƒœë¡œ í•˜ë‚˜ì˜ json ê°ì²´ë¡œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤ (ëª¨ë“  keyì™€ stringì€ í°ë”°ì˜´í‘œ `"`ë¡œ ë‘˜ëŸ¬ìŒˆ)**:
            {{
            "report": "ë¦¬í¬íŠ¸ ë‚´ìš© ì—¬ê¸°ì—",
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"..]
            }}
            """
            
            
            report_response = await self.llm_manager.generate_response(self.current_user_id, prompt)
  
            # ì‘ë‹µ íŒŒì‹±
            comprehensive_report_data = self._parse_llm_response(report_response)
            
            # ìµœê·¼ ì•ŒëŒ ë©”ì‹œì§€ ì €ì¥
            await save_latest_signal(comprehensive_report_data["report"])
            
            
            # 4. ë³´ê³ ì„œ textë§Œ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì „ì†¡ (pdf í˜•ì‹ìœ¼ë¡œ)
            
            report_pdf= self._generate_pdf_report(
                comprehensive_report_data["report"], stock_code
            )
            
            await self.send_weekly_report_telegram(
                stock_code, report_pdf, comprehensive_report_data["keywords"]
            )
            
            # 5. í‚¤ì›Œë“œ vector DB ì €ì¥
            await self.save_keywords_to_vector_db(
                stock_code, comprehensive_report_data["keywords"]
            )
            self.logger.info(f"ì£¼ê°„ ë³´ê³ ì„œ ì²˜ë¦¬ ì™„ë£Œ: {stock_code}")
            return report_pdf


        except Exception as e:
            self.logger.error(f"ì£¼ê°„ ë³´ê³ ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")


    async def run_service(self):
        """ì£¼ê°„ ë³´ê³ ì„œ ì„œë¹„ìŠ¤ ì‹¤í–‰"""
        try:
            self.logger.info("ì£¼ê°„ ë³´ê³ ì„œ ì„œë¹„ìŠ¤ ì‹œì‘")

            # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”

            # ì¢…ëª© ì •ë³´ ë¡œë“œ
            with open(
                project_root / "config" / "stocks.json", "r", encoding="utf-8"
            ) as f:
                stocks_config = json.load(f)

            # ìŠ¤ì¼€ì¤„ ì„¤ì • - ë§¤ì£¼ ì¼ìš”ì¼ 18:00
            def run_weekly_report():
                asyncio.run(self.process_all_stocks(stocks_config))
                #asyncio.create_task(self.process_all_stocks(stocks_config))

            schedule.every().sunday.at("18:00").do(run_weekly_report)

            # ì‹¤í–‰ ë£¨í”„
            while True:
                try:
                    schedule.run_pending()

                    # 1ì‹œê°„ë§ˆë‹¤ ìŠ¤ì¼€ì¤„ ì²´í¬
                    await asyncio.sleep(3600)

                except KeyboardInterrupt:
                    self.logger.info("ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ìš”ì²­")
                    break
                except Exception as e:
                    self.logger.error(f"ì„œë¹„ìŠ¤ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                    await asyncio.sleep(60)

        except Exception as e:
            self.logger.error(f"ì£¼ê°„ ë³´ê³ ì„œ ì„œë¹„ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            self.mysql_client.close()
            self.close_driver()

    async def process_all_stocks(self, stocks_config: Dict):
        """ëª¨ë“  í™œì„± ì¢…ëª© ì²˜ë¦¬"""
        try:
            for stock_code, stock_info in stocks_config.items():
                if stock_info.get("active", False):
                    await self.process_weekly_report(stock_code)

        except Exception as e:
            self.logger.error(f"ì „ì²´ ì¢…ëª© ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
report_service_instance = None
latest_signal_message = None  # ìµœê·¼ ì•ŒëŒ ë©”ì‹œì§€ ì €ì¥

def get_report_service():
    """ë³´ê³ ì„œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global report_service_instance
    if report_service_instance is None:
        report_service_instance = ReportService()
    return report_service_instance

# === FastAPI ì—”ë“œí¬ì¸íŠ¸ ===
@app.post("/set-user/{user_id}")
async def set_user_id_endpoint(user_id: str):
    """ì‚¬ìš©ì ID ì„¤ì • ì—”ë“œí¬ì¸íŠ¸"""
    try:
        report_service = get_report_service()
        await report_service.set_user_id(user_id)
        return {
            "success": True,
            "message": f"ì‚¬ìš©ì ID ì„¤ì • ì™„ë£Œ: {user_id}",
            "user_id": user_id
        }
    except Exception as e:
        logging.error(f"âŒ ì‚¬ìš©ì ID ì„¤ì • ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì‚¬ìš©ì ID ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

@app.get("/user-config/{user_id}")
async def get_user_config_endpoint(user_id: str):
    """ì‚¬ìš©ì ì„¤ì • ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        report_service = get_report_service()
        await report_service.set_user_id(user_id)
        
        # ì‚¬ìš©ì ì„¤ì • ì¡°íšŒ
        user_config = await report_service.user_config_manager.get_user_config(user_id)
        
        return {
            "success": True,
            "user_id": user_id,
            "config": {
                "stocks": user_config.get("stocks", [])
            }
        }
    except Exception as e:
        logging.error(f"âŒ ì‚¬ìš©ì ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì‚¬ìš©ì ì„¤ì • ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/signal")
async def get_signal():
    return get_latest_signal()

async def save_latest_signal(message: str):
    """ìµœê·¼ ì•ŒëŒ ë©”ì‹œì§€ ì €ì¥"""
    global latest_signal_message
    latest_signal_message = {
        "message": message,
        "timestamp": datetime.now().isoformat(),
        "service": "report"
    }

# === FastAPI ì—”ë“œí¬ì¸íŠ¸ ===

@app.get("/signal")
async def get_latest_signal():
    """ìµœê·¼ ì•ŒëŒ ë©”ì‹œì§€ ì¡°íšŒ"""
    global latest_signal_message
    if latest_signal_message:
        return latest_signal_message
    else:
        return {
            "message": "ì•„ì§ ì•ŒëŒì´ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "timestamp": datetime.now().isoformat(),
            "service": "report"
        }

# === ìŠ¤ì¼€ì¤„ë§ ê´€ë ¨ ë³€ìˆ˜ ===
last_execution_time = None

def should_execute_now() -> Tuple[bool, str]:
    """í˜„ì¬ ì‹¤í–‰í•  ì‹œê°„ì¸ì§€ íŒë‹¨ (ì£¼ê°„ ë³´ê³ ì„œ ì „ìš© ë¡œì§)"""
    global last_execution_time
    
    now = datetime.now()
    current_weekday = now.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
    current_time = now.time()
    
    # ì£¼ê°„ ë³´ê³ ì„œ ì‹¤í–‰ ì‹œê°„: ë§¤ì£¼ ì¼ìš”ì¼ ì €ë… 8ì‹œ (20:00)
    target_weekday = 6  # ì¼ìš”ì¼
    target_time = datetime.strptime("20:00", "%H:%M").time()
    
    # ì²« ì‹¤í–‰ì¸ ê²½ìš°
    if last_execution_time is None:
        # ì¼ìš”ì¼ ì €ë…ì¸ì§€ í™•ì¸
        if current_weekday == target_weekday and current_time >= target_time:
            return True, "ì²« ì‹¤í–‰ - ì¼ìš”ì¼ ì €ë…"
        else:
            return False, f"ì£¼ê°„ ë³´ê³ ì„œ ëŒ€ê¸° ì¤‘ - ì¼ìš”ì¼ 20:00 ì‹¤í–‰ ì˜ˆì • (í˜„ì¬: {now.strftime('%A %H:%M')})"
    
    # ë§ˆì§€ë§‰ ì‹¤í–‰ìœ¼ë¡œë¶€í„° ê²½ê³¼ ì‹œê°„ ê³„ì‚°
    time_diff = (now - last_execution_time).total_seconds()
    
    # ì£¼ê°„ ê°„ê²© ì²´í¬ (7ì¼ = 604800ì´ˆ)
    weekly_interval = 7 * 24 * 3600  # 7ì¼
    
    # ì¼ìš”ì¼ ì €ë…ì´ê³ , ì§€ë‚œ ì‹¤í–‰ìœ¼ë¡œë¶€í„° ìµœì†Œ 6ì¼ì´ ì§€ë‚¬ëŠ”ì§€ í™•ì¸
    if (current_weekday == target_weekday and 
        current_time >= target_time and 
        time_diff >= (6 * 24 * 3600)):  # ìµœì†Œ 6ì¼ ê°„ê²©
        return True, f"ì£¼ê°„ ë³´ê³ ì„œ ì‹¤í–‰ ì‹œê°„ - ë§ˆì§€ë§‰ ì‹¤í–‰: {last_execution_time.strftime('%Y-%m-%d %H:%M')}"
    else:
        if current_weekday != target_weekday:
            days_until_sunday = (6 - current_weekday) % 7
            if days_until_sunday == 0:
                days_until_sunday = 7
            return False, f"ì£¼ê°„ ë³´ê³ ì„œ ëŒ€ê¸° ì¤‘ - {days_until_sunday}ì¼ í›„ ì¼ìš”ì¼ ì‹¤í–‰"
        elif current_time < target_time:
            remaining_hours = (datetime.combine(now.date(), target_time) - now).total_seconds() / 3600
            return False, f"ì£¼ê°„ ë³´ê³ ì„œ ëŒ€ê¸° ì¤‘ - {remaining_hours:.1f}ì‹œê°„ í›„ ì‹¤í–‰"
        else:
            remaining_days = 7 - (time_diff / (24 * 3600))
            return False, f"ì£¼ê°„ ë³´ê³ ì„œ ëŒ€ê¸° ì¤‘ - {remaining_days:.1f}ì¼ í›„ ì‹¤í–‰ ê°€ëŠ¥"

async def execute_weekly_report() -> Dict:
    """ì£¼ê°„ ë³´ê³ ì„œ ì‹¤í–‰ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í˜¸ì¶œìš©)"""
    global last_execution_time
    global latest_signal_message
    
    try:
        logging.info("ğŸš€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹ í˜¸ë¡œ ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹œì‘")
        
        # ë¦¬í¬íŠ¸ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        report_service = ReportService()
        
        # ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹¤í–‰
        # Note: ì‹¤ì œ ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ë¡œì§ì€ ReportService í´ë˜ìŠ¤ ë‚´ë¶€ì— êµ¬í˜„ë˜ì–´ ìˆì–´ì•¼ í•¨
        # ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ì ì¸ ì‹¤í–‰ í”„ë ˆì„ì›Œí¬ë§Œ ì œê³µ
        
        processed_stocks = []
        total_reports = 0
        
        # ì‚¬ìš©ì ì„¤ì •ëœ ì¢…ëª©ë“¤ì— ëŒ€í•´ ë³´ê³ ì„œ ìƒì„±
        try:
            stock_items = report_service.stocks_config.items()
            # items()ëŠ” ë˜ì§€ë§Œ ë¹„ì–´ìˆì„ ê²½ìš° ì²´í¬
            if not stock_items:
                raise ValueError("stocks_configê°€ ë¹„ì–´ìˆìŒ")

        except Exception as e:
            logging.warning(f"âš ï¸ ì¢…ëª© ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨ ë˜ëŠ” ë¹„ì–´ìˆìŒ: {e} â†’ ê¸°ë³¸ ì¢…ëª©ìœ¼ë¡œ ëŒ€ì²´")
            stock_items = [("006800", {})]

        for stock_code, _ in stock_items:
        
            try:
                # ë¦¬ì„œì¹˜ ë³´ê³ ì„œ í¬ë¡¤ë§ (ì˜ˆì‹œ)
                logging.info(f"ğŸ“Š {stock_code} ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
                
                # ì‹¤ì œ ë³´ê³ ì„œ ìƒì„± ë¡œì§ì€ ReportService í´ë˜ìŠ¤ì˜ ë©”ì„œë“œë¥¼ í˜¸ì¶œ
                await report_service.process_weekly_report(stock_code)
                
                processed_stocks.append(stock_code)
                total_reports += 1
                
                logging.info(f"âœ… {stock_code} ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
                
            except Exception as e:
                logging.error(f"âŒ {stock_code} ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
                continue
        
        # ì‹¤í–‰ ì‹œê°„ ì—…ë°ì´íŠ¸
        last_execution_time = datetime.now()
        
        result = {
            "success": True,
            "processed_stocks": len(processed_stocks),
            "total_reports": total_reports,
            "execution_time": last_execution_time.isoformat(),
            "next_execution": "ë‹¤ìŒ ì£¼ ì¼ìš”ì¼ 20:00",
            "telegram_message" : latest_signal_message.get("message") if latest_signal_message else None # Add this line
        }
        
        logging.info(f"âœ… ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {len(processed_stocks)}ê°œ ì¢…ëª©, {total_reports}ê°œ ë³´ê³ ì„œ")
        
        # ì™„ë£Œ ì•Œë¦¼ ì €ì¥
        await save_latest_signal(f"ğŸ“Š ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {total_reports}ê°œ ë³´ê³ ì„œ")
        
        return result
        
    except Exception as e:
        logging.error(f"âŒ ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"success": False, "error": str(e)}

@app.post("/execute")
async def execute_report_generation(request: Request):
    """ë¦¬í¬íŠ¸ ìƒì„± ì‹¤í–‰ - ì‚¬ìš©ìë³„ ë™ì  ì²˜ë¦¬"""
    try:
        # Headerì—ì„œ user_id ì¶”ì¶œ (ë¬¸ìì—´ë¡œ ì²˜ë¦¬)
        user_id = request.headers.get("X-User-ID", "1")
        
        # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ì˜ user_id ë™ì  ì—…ë°ì´íŠ¸
        service = get_report_service()
        if service.current_user_id != user_id:
            await service.set_user_id(user_id)
            logging.info(f"ğŸ”„ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë³€ê²½: {user_id}")
        
        # ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹¤í–‰
        result = await execute_weekly_report()
        return result
        
    except Exception as e:
        logging.error(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return {"success": False, "error": str(e)}

@app.post("/check-schedule")
async def check_schedule():
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì²´í¬ ì‹ í˜¸ ìˆ˜ì‹  - ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ì‹œê°„ íŒë‹¨"""
    try:
        should_run, reason = should_execute_now()
        
        if should_run:
            # ì‹¤í–‰ ì¡°ê±´ ë§Œì¡± ì‹œ ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹¤í–‰
            result = await execute_weekly_report()
            
            if result["success"]:
                return {
                    "executed": True,
                    "message": f"ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ - {reason}",
                    "details": result
                }
            else:
                return {
                    "executed": False,
                    "message": f"ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨ - {result.get('error', 'Unknown')}",
                    "reason": reason
                }
        else:
            return {
                "executed": False,
                "message": reason,
                "next_execution": "ë§¤ì£¼ ì¼ìš”ì¼ 20:00"
            }
        
    except Exception as e:
        logging.error(f"âŒ ìŠ¤ì¼€ì¤„ ì²´í¬ ì‹¤íŒ¨: {e}")
        return {
            "executed": False,
            "message": f"ìŠ¤ì¼€ì¤„ ì²´í¬ ì˜¤ë¥˜: {str(e)}"
        }

    # === ì‚¬ìš©ìë³„ ê°œì¸í™” ê¸°ëŠ¥ ===
    
    async def initialize_user_personalization(self):
        """ì‚¬ìš©ì ê°œì¸í™” ì„¤ì • ì´ˆê¸°í™”"""
        try:
            self.user_config_loader = await get_config_loader()
            self.logger.info("âœ… ì‚¬ìš©ì ê°œì¸í™” ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ ì‚¬ìš©ì ê°œì¸í™” ë¡œë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.user_config_loader = None

    async def get_personalized_config(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ìë³„ ê°œì¸í™” ì„¤ì • ì¡°íšŒ"""
        try:
            if not self.user_config_loader:
                self.logger.warning("âš ï¸ ì‚¬ìš©ì ì„¤ì • ë¡œë”ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ - ê¸°ë³¸ê°’ ì‚¬ìš©")
                return self._get_default_config()
            
            # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
            if user_id in self.personalized_configs:
                return self.personalized_configs[user_id]
            
            # APIë¥¼ í†µí•´ ì‚¬ìš©ì ì„¤ì • ë¡œë“œ
            config = await self.user_config_loader.load_user_config(user_id)
            if config:
                # ë¦¬í¬íŠ¸ ì„œë¹„ìŠ¤ì— íŠ¹í™”ëœ ì„¤ì • ì¶”ì¶œ
                personalized_config = {
                    "user_id": user_id,
                    "stocks": [stock["stock_code"] for stock in config.get("stocks", [])],
                    "model_type": config.get("model_type", "hyperclova"),
                    "active_service": config.get("active_services", {}).get("report_service", 0) == 1
                }
                
                # ìºì‹œì— ì €ì¥
                self.personalized_configs[user_id] = personalized_config
                self.logger.info(f"âœ… ì‚¬ìš©ì ê°œì¸í™” ì„¤ì • ë¡œë“œ ì™„ë£Œ: {user_id}")
                return personalized_config
            else:
                self.logger.warning(f"âš ï¸ ì‚¬ìš©ì ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {user_id} - ê¸°ë³¸ê°’ ì‚¬ìš©")
                return self._get_default_config()
                
        except Exception as e:
            self.logger.error(f"âŒ ì‚¬ìš©ì ê°œì¸í™” ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {user_id} - {e}")
            return self._get_default_config()

    def _get_default_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
        return {
            "user_id": "default",
            "stocks": ["005930", "000660"],  # ê¸°ë³¸ ì¢…ëª©: ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤
            "model_type": "hyperclova",
            "active_service": True
        }

    async def should_analyze_for_user(self, user_id: str, stock_code: str) -> bool:
        """íŠ¹ì • ì‚¬ìš©ìì— ëŒ€í•´ í•´ë‹¹ ì¢…ëª©ì„ ë¶„ì„í•´ì•¼ í•˜ëŠ”ì§€ í™•ì¸"""
        try:
            config = await self.get_personalized_config(user_id)
            
            # ì„œë¹„ìŠ¤ê°€ ë¹„í™œì„±í™”ëœ ê²½ìš°
            if not config.get("active_service", True):
                return False
            
            # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì¢…ëª©ì— í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš°
            user_stocks = config.get("stocks", [])
            if stock_code not in user_stocks:
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì‚¬ìš©ìë³„ ë¶„ì„ í•„ìš”ì„± í™•ì¸ ì‹¤íŒ¨: {user_id}, {stock_code} - {e}")
            return True  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ë¶„ì„ ì§„í–‰

    async def get_user_analysis_model(self, user_id: str) -> str:
        """ì‚¬ìš©ìê°€ ì„ íƒí•œ AI ëª¨ë¸ ë°˜í™˜"""
        try:
            config = await self.get_personalized_config(user_id)
            return config.get("model_type", "hyperclova")
        except Exception as e:
            self.logger.error(f"âŒ ì‚¬ìš©ì AI ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {user_id} - {e}")
            return "hyperclova"

    def clear_user_cache(self, user_id: Optional[str] = None):
        """ì‚¬ìš©ì ì„¤ì • ìºì‹œ í´ë¦¬ì–´"""
        if user_id:
            self.personalized_configs.pop(user_id, None)
            if self.user_config_loader:
                self.user_config_loader.clear_cache(user_id)
            self.logger.debug(f"ğŸ§¹ ì‚¬ìš©ì ì„¤ì • ìºì‹œ í´ë¦¬ì–´: {user_id}")
        else:
            self.personalized_configs.clear()
            if self.user_config_loader:
                self.user_config_loader.clear_cache()
            self.logger.debug("ğŸ§¹ ëª¨ë“  ì‚¬ìš©ì ì„¤ì • ìºì‹œ í´ë¦¬ì–´")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("ğŸš€ ë¦¬í¬íŠ¸ ì„œë¹„ìŠ¤ ì‹œì‘ (í¬íŠ¸: 8004)")
        
        # FastAPI ì„œë²„ ì‹¤í–‰
        uvicorn.run(app, host="0.0.0.0", port=8004)
    
    except KeyboardInterrupt:
        print("ì„œë¹„ìŠ¤ ì¤‘ë‹¨")
    except Exception as e:
        print(f"ì„œë¹„ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    #asyncio.run(execute_weekly_report())
    main()
